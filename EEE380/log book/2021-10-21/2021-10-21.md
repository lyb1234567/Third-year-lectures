**Date:21/10/2021**

Today, I basically worked on some mathematical tools mentioned in the reference paper, most of them are about optimizations like KKT, dual problems and so on.

### Math language

- **subject to:** 

  It is a way to specify constraints. To put it very simply, the problem "do 'X' subject to 'Y'" means that, you have to do "X" (whatever X is), but you have to do it such that "Y" is also satisfied in the process.

- **objective function:**

  The objective function in a mathematical optimization problem is the real-valued function whose value is to be either minimized or maximized over the set of feasible alternatives. In problem P above, the function f is the objective function.

- **Two different types of constraints:**

  - Inequality constraints :$g_{i}(x)=0$, $1\le i\le p$
  - equality constraints: $h_{j}(x)\le0, $$1\le j\le q$

- $R^{n}\rightarrow R^{m}$:

  A linear transformation T between two vector spaces $R^{n}$  and  $R^{m}$, written T:$R^{n}\rightarrow R^{m}$ just means that $T$ is a function  that takes as input n-dimensional vectors and gives you m-dimensional vectors. These properties are:
  $$
  \begin{align*}
  1.&T(v+w)=T(v)+T(w)\\
  2.&T(av)=aT(v)
  \end{align*}
  $$
  for all $v,m \in R^{n}$ and a real number.

- **Affine functions:**

  An affine function is a function composed of a linear function + a constant and its graph is a straight line.
  
- **KKT conditions**:

  if we have an optimization problems:
  $$
  \begin{align*}
  &minf(x)\\
  &s.t.g_{i}(x)\le0(j=1,2,\dots,m)\\
  &h_{k}(x)=0(k=1,2,\dots,l)
  \end{align*}
  $$
  

â€‹       If have an optimal value $x^{*}$, and we want to determine it is an optimal value for our optimization, then we can  use KKT conditions to check
$$
\begin{align*}
 \begin{cases}
      &\frac{\delta f}{\delta x_{i}}+\sum_{j=1}^{m}\mu_{j}\frac{\delta g_{j}}{\delta x_{i}}+\sum_{k=1}^{l}\lambda_{k}\frac{\delta h_{k}}{\delta_{x_{i}}}=0,(i=1,2,\dots,n)\\
      & h_{k}(x)=,(k=1,2,\dots,l)\\
      & \mu_{j}g_{j}(x)=0,(j=1,2,\dots,m)\\
      &\mu_{j}\ge0
    \end{cases} 
\end{align*}
$$


### Optimization

 We are trying to maximize the target energy efficiency which belongs to SWIPT-Enabled D2D links.
$$
P1: max \quad EE_{i}^{D}\\
s.t. \quad C1:0<P_{i}^{D}\le P_{max}\\
C2:0\le \lambda_{i}^{e}\le1\\
C3:T_{i}^{D}\ge T_{min}^{D}\\
C4:T_{c}^{k}\ge T_{c}^{min}\\
C5:P_{i}^{R}\ge P_{th}^{1}\\
C6:P_{th}^{j}\le P_{i}^{R}\le P_{th}^{j+1}, j\in0,\dots, L
$$
And for Constraints C1-C5, we have the Lagrange functions:
$$
L(P^{i},\lambda_{i}^{e},\alpha,\beta,\gamma,\delta,\in)=T^{D}_{i}-Q_{i}^{D}EC_{i}^{D}-\alpha(P_{i}^{D}-P_{max})-\beta(\lambda_{i}^{e}-1)+\gamma(T_{i}^{D}-T_{min}^{D})+\\ \delta(T_{i}^{C}-T_{C}^{min})+\in(P_{i}^{R}-P_{th}^{1})
$$
Suppose an objective function f(y) of the constrained optimization problem has a local minimum at the feasible point x. If f(x) and the various constraint functions are continuously differentiable near x, then there exists unit vector of Lagrange multipliers $\lambda_{0},\dots,\lambda_{p}$ and $\mu_{1},\dots\mu q$  such that:
$$
\lambda_{0}\grad f(x)+\sum_{i=1}^{p}\lambda_{i}\ g_{i}(x)+\sum_{j=1}^{q}\grad h_{j}(x)=0
$$
